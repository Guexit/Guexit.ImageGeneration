import unittest
from unittest.mock import ANY, MagicMock, call, patch

import torch
from PIL import Image
import numpy as np

from image_generation.api.models import Prompt, TextToImage
from image_generation.core.schedulers import SchedulerEnum
from image_generation.core.stable_diffusion import (
    AutoPipelineForText2Image,
    StableDiffusionHandler,
)


class TestStableDiffusionHandler(unittest.TestCase):
    def setUp(self):
        self.mocked_pipeline = MagicMock()
        self.original_from_pretrained = AutoPipelineForText2Image.from_pretrained
        AutoPipelineForText2Image.from_pretrained = MagicMock(
            return_value=self.mocked_pipeline
        )

        self.model_path = "test_model_path"

    def tearDown(self):
        AutoPipelineForText2Image.from_pretrained = self.original_from_pretrained

    def get_test_text_to_image(self, num_images=1):
        return TextToImage(
            prompt=Prompt(
                positive="A beautiful landscape with a clear sky",
                negative="bad quality, pixelated",
                guidance_scale=5.0,
            ),
            height=512,
            width=512,
            num_inference_steps=50,
            num_images=num_images,
        )

    def test_init_conditions(self):
        with patch("torch.backends.mps.is_available", return_value=True), patch(
            "torch.cuda.is_available", return_value=False
        ):
            handler = StableDiffusionHandler(self.model_path)
            self.assertEqual(handler.device, torch.device("mps"))

        with patch("torch.backends.mps.is_available", return_value=False), patch(
            "torch.cuda.is_available", return_value=True
        ), patch("torch.cuda.mem_get_info", return_value=(0, 1000000000)), patch(
            "image_generation.core.stable_diffusion.enough_gpu_memory",
            return_value=True,
        ):
            handler = StableDiffusionHandler(self.model_path)
            self.assertEqual(handler.device, torch.device("cuda"))

        with patch("torch.backends.mps.is_available", return_value=False), patch(
            "torch.cuda.is_available", return_value=False
        ), patch("image_generation.utils.enough_gpu_memory", return_value=False):
            handler = StableDiffusionHandler(self.model_path)
            self.assertEqual(handler.device, torch.device("cpu"))

        custom_device = "custom_device"
        with patch("torch.device") as mock_device:
            mock_device.return_value = custom_device
            handler = StableDiffusionHandler(self.model_path, device=custom_device)
        self.assertEqual(handler.device, custom_device)

    def test_txt_to_img(self):
        handler = StableDiffusionHandler(self.model_path)

        test_text_to_image = self.get_test_text_to_image()

        white_img = Image.fromarray(np.ones((512, 512, 3), dtype=np.uint8) * 255)
        handler.pipe.return_value.images = [white_img]

        test_image = handler.txt_to_img(test_text_to_image)

        # Check if the self.pipe() was called with the correct arguments in the last call
        last_call_args = self.mocked_pipeline.call_args_list[-1]
        expected_call = call(
            prompt=test_text_to_image.prompt.positive,
            negative_prompt=test_text_to_image.prompt.negative,
            guidance_scale=test_text_to_image.prompt.guidance_scale,
            height=test_text_to_image.height,
            width=test_text_to_image.width,
            num_inference_steps=test_text_to_image.num_inference_steps,
            num_images_per_prompt=test_text_to_image.num_images,
            generator=handler._set_seed(test_text_to_image.seed),
        )
        self.assertEqual(last_call_args, expected_call)

        # Check if the returned image is the one generated by the mocked pipeline
        self.assertTrue(np.array_equal(test_image[0], white_img))

    def test_pipeline_property(self):
        handler = StableDiffusionHandler(self.model_path)
        self.assertEqual(handler.pipe, self.mocked_pipeline)

    def test_init_with_device(self):
        handler = StableDiffusionHandler(self.model_path, device="cuda")
        self.assertEqual(handler.device, torch.device("cuda"))
        self.assertEqual(handler.model_path, self.model_path)
        self.assertEqual(handler.pipe, self.mocked_pipeline)

    def test_init_without_device(self):
        handler = StableDiffusionHandler(self.model_path)
        self.assertIsNotNone(handler.device)
        self.assertEqual(handler.model_path, self.model_path)
        self.assertEqual(handler.pipe, self.mocked_pipeline)

    def test_init_model(self):
        handler = StableDiffusionHandler(self.model_path)
        new_model_path = "new_model_path"
        new_mocked_pipeline = MagicMock()
        AutoPipelineForText2Image.from_pretrained = MagicMock(
            return_value=new_mocked_pipeline
        )

        handler._init_model(new_model_path)
        self.assertEqual(handler.model_path, new_model_path)
        self.assertEqual(handler.pipe, new_mocked_pipeline)

    # Testing _set_seed method
    def test_set_seed(self):
        handler = StableDiffusionHandler(self.model_path)
        # When seed is -1
        self.assertIsNone(handler._set_seed(-1))

        # When seed is None
        self.assertIsNone(handler._set_seed(None))

        # When seed is a valid integer
        seed = 1234
        generator = handler._set_seed(seed)
        self.assertEqual(generator.initial_seed(), seed)

    # Testing conditions inside the _init_model method
    def test_init_model_cpu(self):
        handler = StableDiffusionHandler(self.model_path, device="cpu")
        self.assertTrue(handler.pipe.enable_sequential_cpu_offload.called)
        handler.pipe.enable_sequential_cpu_offload.assert_called_once()
        handler.pipe.enable_attention_slicing.assert_called_once_with(1)

    def test_init_model_other(self):
        handler = StableDiffusionHandler(self.model_path, device="cuda")
        handler.pipe.enable_attention_slicing.assert_called_once_with(1)
        handler.pipe.to.assert_called_once_with(handler.device)

    # Testing different device scenarios in txt_to_img method
    def test_txt_to_img_mps(self):
        handler = StableDiffusionHandler(self.model_path)
        white_img = Image.fromarray(np.ones((512, 512, 3), dtype=np.uint8) * 255)
        handler.pipe.return_value.images = [white_img]
        handler.device = torch.device("mps")
        handler.txt_to_img(self.get_test_text_to_image())
        handler.pipe.assert_called()

    def test_txt_to_img_other(self):
        handler = StableDiffusionHandler(self.model_path)
        white_img = Image.fromarray(np.ones((512, 512, 3), dtype=np.uint8) * 255)
        handler.pipe.return_value.images = [white_img]
        handler.device = torch.device("cuda")
        handler.txt_to_img(self.get_test_text_to_image())
        handler.pipe.assert_called()

    def test_set_scheduler(self):
        handler = StableDiffusionHandler(self.model_path)
        mock_scheduler = MagicMock()
        with patch(
            "image_generation.core.schedulers.SchedulerHandler.set_scheduler",
            return_value=mock_scheduler,
        ) as mock_set_scheduler:
            scheduler_name = SchedulerEnum.EULER_A

            handler._set_scheduler(scheduler_name)

            mock_set_scheduler.assert_called_once_with(
                scheduler_name=scheduler_name, current_scheduler=ANY
            )
            self.assertEqual(handler.pipe.scheduler, mock_scheduler)
            self.assertEqual(handler.scheduler_name, scheduler_name)

    def test_black_images_success(self):
        handler = StableDiffusionHandler(self.model_path)

        # Create an all-black image and an all-white image
        black_img = Image.fromarray(np.zeros((512, 512, 3), dtype=np.uint8))
        white_img = Image.fromarray(np.ones((512, 512, 3), dtype=np.uint8) * 255)

        def mock_pipe(*args, **kwargs):
            num_images_per_prompt = kwargs.get("num_images_per_prompt", 0)
            return_value = MagicMock()
            if num_images_per_prompt == 1:
                return_value.images = [white_img]
            else:
                return_value.images = [black_img, white_img]
            return return_value

        # Mock the pipe call to return a list with the black and white images
        handler.pipe.side_effect = mock_pipe

        test_text_to_image = self.get_test_text_to_image(num_images=2)
        images = handler.txt_to_img(test_text_to_image)

        # Only the white image should be returned, so length of images should be 1
        self.assertEqual(len(images), 2)

        # Assert the returned images are the white ones
        np.testing.assert_array_equal(images[0], white_img)
        np.testing.assert_array_equal(images[1], white_img)

    def test_black_images_fails_ends_by_retries(self):
        handler = StableDiffusionHandler(self.model_path)

        # Create an all-black image and an all-white image
        black_img = Image.fromarray(np.zeros((512, 512, 3), dtype=np.uint8))
        white_img = Image.fromarray(np.ones((512, 512, 3), dtype=np.uint8) * 255)

        def mock_pipe(*args, **kwargs):
            num_images_per_prompt = kwargs.get("num_images_per_prompt", 0)
            return_value = MagicMock()
            if num_images_per_prompt == 1:
                return_value.images = [black_img]
            else:
                return_value.images = [black_img, white_img]
            return return_value

        # Mock the pipe call to return a list with the black and white images
        handler.pipe.side_effect = mock_pipe

        test_text_to_image = self.get_test_text_to_image(num_images=2)
        images = handler.txt_to_img(test_text_to_image)

        # Only the white image should be returned, so length of images should be 1
        self.assertEqual(len(images), 1)

        # Assert the returned images are the white ones
        np.testing.assert_array_equal(images[0], white_img)


if __name__ == "__main__":
    unittest.main()
